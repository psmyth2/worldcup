{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter REST APIs provide read and write access to existing Twitter data. There are a lot of useful APIs in this collection, but we only need to discuss the Search API for our purposes.The Twitter Search API is used to search a random sample of the past week of tweets. Note that the Search API does not capture every tweet in the past week — it aims for “relevance, not completeness.”\n",
    "\n",
    "This will work well for pupose of capturing a representative samples of World Cup sentiment tweets from within the U.S for the past week of play (the semi-final games on Tue. 7/10 and Wed. 7/11., third place Sat.7/14 game and final Sun. 7/15). This harvest was collected on Sun. 7/15 following the conclusion of the Final (France beat Croatia). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tweepy\n",
    "import jsonpickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key=\"WJplbIJsJOW4l1iWvpIJA4s0K\"\n",
    "consumer_secret=\"HbyyxE5hJcUR58419edGM1SJCp07hcAzmIP3YU4DitAEJATGIj\"\n",
    "access_key=\"99735645-gRIyDayEgb8tJhPwVPk0VBGxTtNzTR3eyZH4xwZPn\"\n",
    "access_secret=\"wBC6E4bf5Yro3Ycyst93QS7cuNJq9CtkOpdBG2e8WRi6W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA id is:  96683cc9126741d1\n"
     ]
    }
   ],
   "source": [
    "#Pass our consumer key and consumer secret to Tweepy's user authentication handler\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "#Pass our access token and access secret to Tweepy's user authentication handler\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "\n",
    "#Creating a twitter API wrapper using tweepy\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Error handling\n",
    "if (not api):\n",
    "    print (\"Problem connecting to API\")\n",
    "    \n",
    "#Getting Geo ID for U.S\n",
    "places = api.geo_search(query=\"USA\", granularity=\"country\")\n",
    "\n",
    "#Copy USA id\n",
    "place_id = places[0].id\n",
    "print('USA id is: ',place_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Switching to application authentication\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "#Setting up new api wrapper, using authentication only\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "\n",
    "#Error handling\n",
    "if (not api):\n",
    "    print (\"Problem Connecting to API\")\n",
    "\n",
    "#You can check how many queries you have left using rate_limit_status() method\n",
    "api.rate_limit_status()['resources']['search']\n",
    "\n",
    "#This is what we are searching for\n",
    "#We can restrict the location of tweets using place:id \n",
    "#We can search for multiple phrases using OR\n",
    "searchQuery = 'place:96683cc9126741d1 #France OR #Croatia OR #England OR #Belgium OR #WorldCup OR #WorldCupFinal'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 33 tweets\n"
     ]
    }
   ],
   "source": [
    "#Maximum number of tweets we want to collect \n",
    "maxTweets = 1000000\n",
    "\n",
    "#The twitter Search API allows up to 100 tweets per query\n",
    "tweetsPerQry = 100\n",
    "\n",
    "tweetCount = 0\n",
    "\n",
    "#Open a text file to save the tweets to\n",
    "with open('worldcupsentiments07172018.json', 'w') as f:\n",
    "\n",
    "    #Tell the Cursor method that we want to use the Search API (api.search)\n",
    "    #Also tell Cursor our query, and the maximum number of tweets to return\n",
    "    for tweet in tweepy.Cursor(api.search,q=searchQuery).items(maxTweets) :         \n",
    "\n",
    "        #Verify the tweet has place info before writing (It should, if it got past our place filter)\n",
    "        if tweet.place is not None:\n",
    "            \n",
    "            #Write the JSON format to the text file, and add one to the number of tweets we've collected\n",
    "            f.write(jsonpickle.encode(tweet._json, unpicklable=False) + '\\n')\n",
    "            tweetCount += 1\n",
    "\n",
    "    #Display how many tweets we have collected\n",
    "    print(\"Downloaded {0} tweets\".format(tweetCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': {'coordinates': [-115.16716007, 36.12705064], 'type': 'Point'},\n",
       " 'created_at': 'Tue Jul 17 01:41:47 +0000 2018',\n",
       " 'entities': {'hashtags': [{'indices': [54, 73], 'text': 'sportshandicapping'},\n",
       "   {'indices': [74, 86], 'text': 'handicapper'},\n",
       "   {'indices': [87, 100], 'text': 'handicapping'},\n",
       "   {'indices': [101, 105], 'text': 'mlb'},\n",
       "   {'indices': [106, 115], 'text': 'baseball'}],\n",
       "  'symbols': [],\n",
       "  'urls': [{'display_url': 'twitter.com/i/web/status/1…',\n",
       "    'expanded_url': 'https://twitter.com/i/web/status/1019034395531993088',\n",
       "    'indices': [117, 140],\n",
       "    'url': 'https://t.co/MvUHQoTP9o'}],\n",
       "  'user_mentions': []},\n",
       " 'favorite_count': 1,\n",
       " 'favorited': False,\n",
       " 'geo': {'coordinates': [36.12705064, -115.16716007], 'type': 'Point'},\n",
       " 'id': 1019034395531993088,\n",
       " 'id_str': '1019034395531993088',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'en',\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'place': {'attributes': {},\n",
       "  'bounding_box': {'coordinates': [[[-115.2092535, 35.984784],\n",
       "     [-115.0610763, 35.984784],\n",
       "     [-115.0610763, 36.137145],\n",
       "     [-115.2092535, 36.137145]]],\n",
       "   'type': 'Polygon'},\n",
       "  'contained_within': [],\n",
       "  'country': 'United States',\n",
       "  'country_code': 'US',\n",
       "  'full_name': 'Paradise, NV',\n",
       "  'id': '8fa6d7a33b83ef26',\n",
       "  'name': 'Paradise',\n",
       "  'place_type': 'city',\n",
       "  'url': 'https://api.twitter.com/1.1/geo/id/8fa6d7a33b83ef26.json'},\n",
       " 'possibly_sensitive': False,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': False,\n",
       " 'source': '<a href=\"http://instagram.com\" rel=\"nofollow\">Instagram</a>',\n",
       " 'text': 'NO DAYS OFF! The best to ever do it. No matter what.  #sportshandicapping #handicapper #handicapping #mlb #baseball… https://t.co/MvUHQoTP9o',\n",
       " 'truncated': True,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Wed Jan 21 20:05:17 +0000 2015',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'description': 'The Best Sports Handicapping Firm In The World. \\n\\nhttps://t.co/SVfFVfEne2 \\n\\nText 702-664-8653 for your first VIP Winner FREE on us!',\n",
       "  'entities': {'description': {'urls': [{'display_url': 'linktr.ee/thesportstrade…',\n",
       "      'expanded_url': 'https://linktr.ee/thesportstraders',\n",
       "      'indices': [50, 73],\n",
       "      'url': 'https://t.co/SVfFVfEne2'}]},\n",
       "   'url': {'urls': [{'display_url': 'thesportstraders.com',\n",
       "      'expanded_url': 'http://www.thesportstraders.com',\n",
       "      'indices': [0, 23],\n",
       "      'url': 'https://t.co/NcO4qg2Mu6'}]}},\n",
       "  'favourites_count': 28,\n",
       "  'follow_request_sent': None,\n",
       "  'followers_count': 2128,\n",
       "  'following': None,\n",
       "  'friends_count': 1787,\n",
       "  'geo_enabled': True,\n",
       "  'has_extended_profile': True,\n",
       "  'id': 2990461107,\n",
       "  'id_str': '2990461107',\n",
       "  'is_translation_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 3,\n",
       "  'location': 'Las Vegas, NV',\n",
       "  'name': 'The Sports Traders',\n",
       "  'notifications': None,\n",
       "  'profile_background_color': '000000',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2990461107/1525722351',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/993568293201039361/sJSssgcK_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/993568293201039361/sJSssgcK_normal.jpg',\n",
       "  'profile_link_color': 'E81C4F',\n",
       "  'profile_sidebar_border_color': '000000',\n",
       "  'profile_sidebar_fill_color': '000000',\n",
       "  'profile_text_color': '000000',\n",
       "  'profile_use_background_image': False,\n",
       "  'protected': False,\n",
       "  'screen_name': 'tst_sports',\n",
       "  'statuses_count': 878,\n",
       "  'time_zone': None,\n",
       "  'translator_type': 'none',\n",
       "  'url': 'https://t.co/NcO4qg2Mu6',\n",
       "  'utc_offset': None,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at what we are actually printing to text\n",
    "tweet._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_api\n",
      "_json\n",
      "author\n",
      "contributors\n",
      "coordinates\n",
      "created_at\n",
      "destroy\n",
      "entities\n",
      "favorite\n",
      "favorite_count\n",
      "favorited\n",
      "geo\n",
      "id\n",
      "id_str\n",
      "in_reply_to_screen_name\n",
      "in_reply_to_status_id\n",
      "in_reply_to_status_id_str\n",
      "in_reply_to_user_id\n",
      "in_reply_to_user_id_str\n",
      "is_quote_status\n",
      "lang\n",
      "metadata\n",
      "parse\n",
      "parse_list\n",
      "place\n",
      "possibly_sensitive\n",
      "retweet\n",
      "retweet_count\n",
      "retweeted\n",
      "retweets\n",
      "source\n",
      "source_url\n",
      "text\n",
      "truncated\n",
      "user\n"
     ]
    }
   ],
   "source": [
    "#A function to clean up and print all of the JSON attributes \n",
    "def PrintMembers(obj):\n",
    "    for attribute in dir(obj):\n",
    "        \n",
    "        #We don't want to show built in methods of the class\n",
    "        if not attribute.startswith('__'):\n",
    "            print(attribute)\n",
    "            \n",
    "PrintMembers(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_tweets(path):\n",
    "    #Declare a new data frame with pandas, with some specific column names\n",
    "    tweets = pd.DataFrame(columns=['screenName','userId','text','location'])\n",
    "\n",
    "    #Open the text file that contains the tweets we collected\n",
    "    tweets_file = open(path, \"r\")\n",
    "    \n",
    "    #Read the text file line by line\n",
    "    for line in tweets_file:\n",
    "        \n",
    "        #Load the JSON information\n",
    "        tweet = json.loads(line)\n",
    "        \n",
    "        #If the tweet isn't empty, add it to the data frame\n",
    "        if ('text' in tweet): \n",
    "            tweets.loc[len(tweets)]=[tweet['user']['screen_name'],\\\n",
    "            tweet['user']['id'],tweet['text'],tweet['place']['full_name']]    \n",
    "\n",
    "    return tweets\n",
    "\n",
    "WorldCup_tweets = pop_tweets('worldcupsentiments07172018.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HABBENINK</td>\n",
       "      <td>30084883</td>\n",
       "      <td>Chapeau de poisson. #sketchbook #drawing #illu...</td>\n",
       "      <td>Holladay, UT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minda33</td>\n",
       "      <td>18010616</td>\n",
       "      <td>It is not too late for this important #WorldCu...</td>\n",
       "      <td>Iowa, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ronnieisrunning</td>\n",
       "      <td>364544742</td>\n",
       "      <td>https://t.co/2JKhsekx3F 6,948 days in a row. #...</td>\n",
       "      <td>Dallas, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>johnnykera</td>\n",
       "      <td>179530315</td>\n",
       "      <td>Like I said, we still celebrate after a loss. ...</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TexSR_Tanner1</td>\n",
       "      <td>2477561683</td>\n",
       "      <td>@cosmicfunpalace @ohJuliatweets @RobertB_Rice ...</td>\n",
       "      <td>Flower Mound, TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        screenName      userId  \\\n",
       "0        HABBENINK    30084883   \n",
       "1          minda33    18010616   \n",
       "2  ronnieisrunning   364544742   \n",
       "3       johnnykera   179530315   \n",
       "4    TexSR_Tanner1  2477561683   \n",
       "\n",
       "                                                text          location  \n",
       "0  Chapeau de poisson. #sketchbook #drawing #illu...      Holladay, UT  \n",
       "1  It is not too late for this important #WorldCu...         Iowa, USA  \n",
       "2  https://t.co/2JKhsekx3F 6,948 days in a row. #...        Dallas, TX  \n",
       "3  Like I said, we still celebrate after a loss. ...   Los Angeles, CA  \n",
       "4  @cosmicfunpalace @ohJuliatweets @RobertB_Rice ...  Flower Mound, TX  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WorldCup_tweets.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like I said, we still celebrate after a loss. #california #croatia #love #losangeles #Instagram #video #croat… https://t.co/Fzj4Mxu2gT\n"
     ]
    }
   ],
   "source": [
    "print(WorldCup_tweets['text'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
